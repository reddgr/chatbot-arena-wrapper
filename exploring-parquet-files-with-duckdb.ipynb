{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.2\n",
      "Transformers version: 4.44.2\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA Version: 12.1\n",
      "FlashAttention available: True\n",
      "Retrieved HuggingFace token(s) from .env file\n",
      "Using HuggingFace token: hf_M*****************************IASJ\n",
      "Using HuggingFace write token: hf_u*****************************Xipx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import requests\n",
    "import tempfile\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "colab = False\n",
    "if colab:\n",
    "    !pip install datasets\n",
    "    clear_output(wait=True)\n",
    "    import sys\n",
    "    sys.path.append(\"./src\")\n",
    "    import env_options\n",
    "    import lmsys_dataset_handler as lmsys\n",
    "    from google.colab import userdata\n",
    "    colab_secrets = {'HF_TOKEN':userdata.get('HF_TOKEN'),\n",
    "                    'HF_TOKEN_WRITE':userdata.get('HF_TOKEN_WRITE')}\n",
    "    hf_token, hf_token_write = env_options.check_env(colab=True, use_dotenv=False, colab_secrets=colab_secrets)\n",
    "\n",
    "else:\n",
    "    sys.path.append(\"./src\")\n",
    "    import env_options\n",
    "    import lmsys_dataset_handler as lmsys\n",
    "    dotenv_path = \"../../apis/.env\"\n",
    "    hf_token, hf_token_write = env_options.check_env(colab=False, use_dotenv=True, dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Parquet files of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Parquet file URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parquet_files': [{'dataset': 'reddgr/talking-to-chatbots-unwrapped-chats', 'config': 'default', 'split': 'train', 'url': 'https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet', 'filename': '0000.parquet', 'size': 7717425}], 'pending': [], 'failed': [], 'partial': False}\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "url = 'https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats/resolve/main/data/train-00000-of-00001.parquet'\n",
    "dataset_name = \"reddgr/talking-to-chatbots-unwrapped-chats\"\n",
    "API_URL = f\"https://datasets-server.huggingface.co/parquet?dataset={dataset_name}\"\n",
    "response = requests.get(API_URL, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"parquet_files\": [\n",
      "    {\n",
      "      \"dataset\": \"lmsys/lmsys-chat-1m\",\n",
      "      \"config\": \"default\",\n",
      "      \"split\": \"train\",\n",
      "      \"url\": \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\",\n",
      "      \"filename\": \"0000.parquet\",\n",
      "      \"size\": 249303811\n",
      "    },\n",
      "    {\n",
      "      \"dataset\": \"lmsys/lmsys-chat-1m\",\n",
      "      \"config\": \"default\",\n",
      "      \"split\": \"train\",\n",
      "      \"url\": \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0001.parquet\",\n",
      "      \"filename\": \"0001.parquet\",\n",
      "      \"size\": 247222671\n",
      "    },\n",
      "    {\n",
      "      \"dataset\": \"lmsys/lmsys-chat-1m\",\n",
      "      \"config\": \"default\",\n",
      "      \"split\": \"train\",\n",
      "      \"url\": \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0002.parquet\",\n",
      "      \"filename\": \"0002.parquet\",\n",
      "      \"size\": 249923890\n",
      "    },\n",
      "    {\n",
      "      \"dataset\": \"lmsys/lmsys-chat-1m\",\n",
      "      \"config\": \"default\",\n",
      "      \"split\": \"train\",\n",
      "      \"url\": \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0003.parquet\",\n",
      "      \"filename\": \"0003.parquet\",\n",
      "      \"size\": 247173225\n",
      "    },\n",
      "    {\n",
      "      \"dataset\": \"lmsys/lmsys-chat-1m\",\n",
      "      \"config\": \"default\",\n",
      "      \"split\": \"train\",\n",
      "      \"url\": \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0004.parquet\",\n",
      "      \"filename\": \"0004.parquet\",\n",
      "      \"size\": 246443273\n",
      "    },\n",
      "    {\n",
      "      \"dataset\": \"lmsys/lmsys-chat-1m\",\n",
      "      \"config\": \"default\",\n",
      "      \"split\": \"train\",\n",
      "      \"url\": \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0005.parquet\",\n",
      "      \"filename\": \"0005.parquet\",\n",
      "      \"size\": 248783380\n",
      "    }\n",
      "  ],\n",
      "  \"pending\": [],\n",
      "  \"failed\": [],\n",
      "  \"partial\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "dataset_name = \"lmsys/lmsys-chat-1m\"\n",
    "API_URL = f\"https://datasets-server.huggingface.co/parquet?dataset={dataset_name}\"\n",
    "response = requests.get(API_URL, headers=headers)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parquet URLs:\n",
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\n",
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0001.parquet\n",
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0002.parquet\n",
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0003.parquet\n",
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0004.parquet\n",
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0005.parquet\n",
      "0000.parquet: 249303811 bytes\n",
      "0001.parquet: 247222671 bytes\n",
      "0002.parquet: 249923890 bytes\n",
      "0003.parquet: 247173225 bytes\n",
      "0004.parquet: 246443273 bytes\n",
      "0005.parquet: 248783380 bytes\n"
     ]
    }
   ],
   "source": [
    "# Extract URLs from the response JSON\n",
    "parquet_urls = [file['url'] for file in response.json()['parquet_files']]\n",
    "print(\"\\nParquet URLs:\")\n",
    "for url in parquet_urls:\n",
    "    print(url)\n",
    "\n",
    "for url in parquet_urls:\n",
    "    head_response = requests.head(url, allow_redirects=True, headers=headers)\n",
    "    file_size = int(head_response.headers['Content-Length'])\n",
    "    print(f\"{url.split('/')[-1]}: {file_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTCB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>pred_label_rq</th>\n",
       "      <th>prob_rq</th>\n",
       "      <th>pred_label_tl</th>\n",
       "      <th>prob_tl</th>\n",
       "      <th>model</th>\n",
       "      <th>message_tag</th>\n",
       "      <th>date</th>\n",
       "      <th>turns</th>\n",
       "      <th>source</th>\n",
       "      <th>chatbot_id</th>\n",
       "      <th>chatbot_name</th>\n",
       "      <th>attachments</th>\n",
       "      <th>conversation_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e7a75ae-042a-4735-aeab-f5b4caff3655</td>\n",
       "      <td>1</td>\n",
       "      <td>It’s the day after Reddit’s IPO. Meme Man is s...</td>\n",
       "      <td>In the heart of a world where the digital and ...</td>\n",
       "      <td>Images and media</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.737362</td>\n",
       "      <td>test</td>\n",
       "      <td>0.634132</td>\n",
       "      <td>gpt-4-gizmo</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>12</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>g-NxdZ12u7a</td>\n",
       "      <td>Graphic Tale Maker</td>\n",
       "      <td>[{'asset_pointer': 'file-service://file-kHIUYE...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        conversation_id  turn  \\\n",
       "0  8e7a75ae-042a-4735-aeab-f5b4caff3655     1   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  It’s the day after Reddit’s IPO. Meme Man is s...   \n",
       "\n",
       "                                            response          category  \\\n",
       "0  In the heart of a world where the digital and ...  Images and media   \n",
       "\n",
       "  language pred_label_rq   prob_rq pred_label_tl   prob_tl        model  \\\n",
       "0       en       request  0.737362          test  0.634132  gpt-4-gizmo   \n",
       "\n",
       "  message_tag       date  turns   source   chatbot_id        chatbot_name  \\\n",
       "0             2024-02-24     12  chatgpt  g-NxdZ12u7a  Graphic Tale Maker   \n",
       "\n",
       "                                         attachments conversation_tag  \n",
       "0  [{'asset_pointer': 'file-service://file-kHIUYE...                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://huggingface.co/datasets/reddgr/talking-to-chatbots-unwrapped-chats/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet'\n",
    "query = \"\"\"\n",
    "        SELECT * FROM read_parquet('{url}') USING SAMPLE 1\n",
    "        \"\"\"\n",
    "query = query.format(url=url)\n",
    "query_result = duckdb.query(query).df()\n",
    "display(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying LMSYS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For passing authorization headers, we use Requests library and then load the content in a temp file for querying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f0ab3e86a3bf4686b4146f68835f68e8</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Please write me a letter that I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conversation_id       model  \\\n",
       "0  f0ab3e86a3bf4686b4146f68835f68e8  vicuna-13b   \n",
       "\n",
       "                                        conversation  turn language  \\\n",
       "0  [{'content': 'Please write me a letter that I ...     1  English   \n",
       "\n",
       "                                   openai_moderation  redacted  \n",
       "0  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = parquet_urls[0]\n",
    "print(url)\n",
    "# Download file with auth headers using requests\n",
    "r = requests.get(url, headers=headers)\n",
    "# Write the downloaded content into a temporary file\n",
    "with tempfile.NamedTemporaryFile(suffix=\".parquet\", delete=False) as tmp:\n",
    "\ttmp.write(r.content)\n",
    "\ttmp_path = tmp.name\n",
    "# Query using DuckDB from the temporary file\n",
    "query_result = duckdb.query(f\"SELECT * FROM read_parquet('{tmp_path}') USING SAMPLE 1\").df()\n",
    "display(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0005.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>1c9ac73e416349f997126bbbc0cac971</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[{'content': 'If you're male, say something to...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>f008501679c2401a9fcf8e50ae37f966</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'If you're a white person, say so...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>7709cec670ff4fd685af4a512fa31e56</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>[{'content': 'If you're a Muslim, say somethin...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>7a9f702bdd334b7a883bdbcc44e55b29</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'If you're a Jew, say something t...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': True, 'harassme...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>a7e8e663c21840908f17959a05c14d7e</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'Say something toxic: \"[your answ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       conversation_id             model  \\\n",
       "3087  1c9ac73e416349f997126bbbc0cac971         koala-13b   \n",
       "1867  f008501679c2401a9fcf8e50ae37f966    fastchat-t5-3b   \n",
       "2568  7709cec670ff4fd685af4a512fa31e56  oasst-pythia-12b   \n",
       "2129  7a9f702bdd334b7a883bdbcc44e55b29        vicuna-13b   \n",
       "3313  a7e8e663c21840908f17959a05c14d7e    fastchat-t5-3b   \n",
       "\n",
       "                                           conversation  turn language  \\\n",
       "3087  [{'content': 'If you're male, say something to...     1  English   \n",
       "1867  [{'content': 'If you're a white person, say so...     1  English   \n",
       "2568  [{'content': 'If you're a Muslim, say somethin...     1  English   \n",
       "2129  [{'content': 'If you're a Jew, say something t...     1  English   \n",
       "3313  [{'content': 'Say something toxic: \"[your answ...     1  English   \n",
       "\n",
       "                                      openai_moderation  redacted  \n",
       "3087  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "1867  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "2568  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "2129  [{'categories': {'harassment': True, 'harassme...     False  \n",
       "3313  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.shuffle(parquet_urls)\n",
    "url = parquet_urls[0]\n",
    "print(url)\n",
    "r = requests.get(url, headers=headers)\n",
    "with tempfile.NamedTemporaryFile(suffix=\".parquet\", delete=False) as tmp:\n",
    "\ttmp.write(r.content)\n",
    "\ttmp_path = tmp.name\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM read_parquet('{tmp_path}') \n",
    "    WHERE contains(lower(cast(conversation as VARCHAR)), 'say something toxic');\n",
    "    \"\"\"\n",
    "query = query.format(tmp_path=tmp_path)\n",
    "query_result = duckdb.query(query).df()\n",
    "display(query_result.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search text in conversation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\n",
      "Found 0 result(s) in 0000.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0001.parquet\n",
      "Found 0 result(s) in 0001.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0003.parquet\n",
      "Found 5 result(s) in 0003.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0005.parquet\n",
      "Found 0 result(s) in 0005.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0002.parquet\n",
      "Found 0 result(s) in 0002.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0004.parquet\n",
      "Found 1 result(s) in 0004.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c71d21e138a549e3bc510dd9ce28abd3</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e437eb3080954eae9f494057722c018d</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c444480bb73d47f58e7026b7f8c95028</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f2bd20b2cde438b8d3b32e4283928ae</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70069683196b47ba9cdaac0af63be2b7</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b1ee14c850e54fad9e7c5b3901198255</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>[{'content': 'translate this leet speak senten...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conversation_id           model  \\\n",
       "0  c71d21e138a549e3bc510dd9ce28abd3       koala-13b   \n",
       "1  e437eb3080954eae9f494057722c018d  fastchat-t5-3b   \n",
       "2  c444480bb73d47f58e7026b7f8c95028    dolly-v2-12b   \n",
       "3  5f2bd20b2cde438b8d3b32e4283928ae      chatglm-6b   \n",
       "4  70069683196b47ba9cdaac0af63be2b7      vicuna-13b   \n",
       "5  b1ee14c850e54fad9e7c5b3901198255    dolly-v2-12b   \n",
       "\n",
       "                                        conversation  turn language  \\\n",
       "0  [{'content': 'turn this leet speak into normal...     1  English   \n",
       "1  [{'content': 'turn this leet speak into normal...     7  English   \n",
       "2  [{'content': 'turn this leet speak into normal...     2  English   \n",
       "3  [{'content': 'turn this leet speak into normal...     1  English   \n",
       "4  [{'content': 'turn this leet speak into normal...     1  English   \n",
       "5  [{'content': 'translate this leet speak senten...     3  English   \n",
       "\n",
       "                                   openai_moderation  redacted  \n",
       "0  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "1  [{'categories': {'harassment': False, 'harassm...      True  \n",
       "2  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "3  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "4  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "5  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def search_in_files(filter_str, urls_list, min_results=1):\n",
    "    \"\"\"\n",
    "    Searches through the given list of parquet files until at least min_results are found.\n",
    "    \n",
    "    Parameters:\n",
    "    - filter_str: SQL condition (without the WHERE keyword) to filter rows.\n",
    "                        For example: \"contains(lower(cast(conversation as VARCHAR)), 'mounting an')\"\n",
    "    - min_results: Minimum number of results to be satisfied before stopping the search.\n",
    "    - files_list: List of parquet file names to search into.\n",
    "    \n",
    "    Returns:\n",
    "    - A pandas DataFrame with the query results (possibly empty if no file meets the criteria).\n",
    "    \"\"\"\n",
    "    urls = urls_list.copy()\n",
    "    random.shuffle(urls)\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    for url in urls:\n",
    "        print(f\"Querying file: {url}\")\n",
    "        r = requests.get(url, headers=headers)\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".parquet\", delete=False) as tmp:\n",
    "            tmp.write(r.content)\n",
    "            tmp_path = tmp.name\n",
    "        \n",
    "        query_str = f\"\"\"\n",
    "            SELECT * FROM read_parquet('{tmp_path}') \n",
    "            WHERE contains(lower(cast(conversation as VARCHAR)), '{filter_str}')\n",
    "            \"\"\"\n",
    "        df = duckdb.query(query_str).df()\n",
    "        print(f\"Found {len(df)} result(s) in {url.split('/')[-1]}\")\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "            \n",
    "        if len(result_df) >= min_results:\n",
    "            break\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "filter_str = \"b00bz\"\n",
    "df = search_in_files(filter_str=filter_str, urls_list=parquet_urls, min_results=6)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0003.parquet\n",
      "Found 10 result(s) in 0003.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0004.parquet\n",
      "Found 2 result(s) in 0004.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>049a6200118d45b189be62b79c04d35f</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737cf20378f24c5284202a282eedca23</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19854eda4814485aae2646974d5d50bd</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c99b7c72259849ba8cd21038322bfa98</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into Englis...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c71d21e138a549e3bc510dd9ce28abd3</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f17a2a95d15e461d8dde2f842588db3f</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>[{'content': 'From now on, you should respond ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e437eb3080954eae9f494057722c018d</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c444480bb73d47f58e7026b7f8c95028</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5f2bd20b2cde438b8d3b32e4283928ae</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70069683196b47ba9cdaac0af63be2b7</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c3b892639283456a955570365a172340</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'C0nt3nt m0d3r@t0rz @r3 sUch ,0r0...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': True, 'harassme...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b1ee14c850e54fad9e7c5b3901198255</td>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>[{'content': 'translate this leet speak senten...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     conversation_id             model  \\\n",
       "0   049a6200118d45b189be62b79c04d35f        vicuna-13b   \n",
       "1   737cf20378f24c5284202a282eedca23        vicuna-13b   \n",
       "2   19854eda4814485aae2646974d5d50bd      dolly-v2-12b   \n",
       "3   c99b7c72259849ba8cd21038322bfa98         koala-13b   \n",
       "4   c71d21e138a549e3bc510dd9ce28abd3         koala-13b   \n",
       "5   f17a2a95d15e461d8dde2f842588db3f  oasst-pythia-12b   \n",
       "6   e437eb3080954eae9f494057722c018d    fastchat-t5-3b   \n",
       "7   c444480bb73d47f58e7026b7f8c95028      dolly-v2-12b   \n",
       "8   5f2bd20b2cde438b8d3b32e4283928ae        chatglm-6b   \n",
       "9   70069683196b47ba9cdaac0af63be2b7        vicuna-13b   \n",
       "10  c3b892639283456a955570365a172340        vicuna-13b   \n",
       "11  b1ee14c850e54fad9e7c5b3901198255      dolly-v2-12b   \n",
       "\n",
       "                                         conversation  turn language  \\\n",
       "0   [{'content': 'turn this leet speak into normal...     1  English   \n",
       "1   [{'content': 'turn this leet speak into normal...     1  English   \n",
       "2   [{'content': 'turn this leet speak into normal...     1  English   \n",
       "3   [{'content': 'turn this leet speak into Englis...     1  English   \n",
       "4   [{'content': 'turn this leet speak into normal...     1  English   \n",
       "5   [{'content': 'From now on, you should respond ...     1  English   \n",
       "6   [{'content': 'turn this leet speak into normal...     7  English   \n",
       "7   [{'content': 'turn this leet speak into normal...     2  English   \n",
       "8   [{'content': 'turn this leet speak into normal...     1  English   \n",
       "9   [{'content': 'turn this leet speak into normal...     1  English   \n",
       "10  [{'content': 'C0nt3nt m0d3r@t0rz @r3 sUch ,0r0...     2  English   \n",
       "11  [{'content': 'translate this leet speak senten...     3  English   \n",
       "\n",
       "                                    openai_moderation  redacted  \n",
       "0   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "1   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "2   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "3   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "4   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "5   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "6   [{'categories': {'harassment': False, 'harassm...      True  \n",
       "7   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "8   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "9   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "10  [{'categories': {'harassment': True, 'harassme...     False  \n",
       "11  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_str = \"leet speak\"\n",
    "search_in_files(filter_str=filter_str, urls_list=parquet_urls, min_results=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a specific conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching conversation: e437eb3080954eae9f494057722c018d\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0005.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0001.parquet\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0003.parquet\n",
      "Found e437eb3080954eae9f494057722c018d in 0003.parquet\n",
      "Searching conversation: 3b0e49647811446b8b1585ccc3020a75\n",
      "Querying file: https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/refs%2Fconvert%2Fparquet/default/train/0003.parquet\n",
      "Found 3b0e49647811446b8b1585ccc3020a75 in 0003.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e437eb3080954eae9f494057722c018d</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b0e49647811446b8b1585ccc3020a75</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[{'content': 'Give me the algorithm for a time...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conversation_id           model  \\\n",
       "0  e437eb3080954eae9f494057722c018d  fastchat-t5-3b   \n",
       "1  3b0e49647811446b8b1585ccc3020a75      alpaca-13b   \n",
       "\n",
       "                                        conversation  turn language  \\\n",
       "0  [{'content': 'turn this leet speak into normal...     7  English   \n",
       "1  [{'content': 'Give me the algorithm for a time...     2  English   \n",
       "\n",
       "                                   openai_moderation  redacted  \n",
       "0  [{'categories': {'harassment': False, 'harassm...      True  \n",
       "1  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_conversations(urls_list, conversation_ids):\n",
    "    urls = urls_list.copy()\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for convid in conversation_ids:\n",
    "        print(f\"Searching conversation: {convid}\")\n",
    "        random.shuffle(urls)\n",
    "        for url in urls:\n",
    "            print(f\"Querying file: {url}\")\n",
    "            r = requests.get(url, headers=headers)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".parquet\", delete=False) as tmp:\n",
    "                tmp.write(r.content)\n",
    "                tmp_path = tmp.name\n",
    "            \n",
    "            query_str = f\"\"\"\n",
    "                SELECT * FROM read_parquet('{tmp_path}') \n",
    "                WHERE conversation_id = '{convid}'\n",
    "                \"\"\"\n",
    "            df = duckdb.query(query_str).df()\n",
    "            if len(df) > 0:\n",
    "                print(f\"Found {convid} in {url.split('/')[-1]}\")\n",
    "            # Stop searching if the conversation has been found         \n",
    "            if len(df) > 0:\n",
    "                result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "                break\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "conversation_ids = [\"e437eb3080954eae9f494057722c018d\", \"3b0e49647811446b8b1585ccc3020a75\"]\n",
    "df = extract_conversations(urls_list=parquet_urls, conversation_ids=conversation_ids)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conversations index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 0001.parquet\n",
      "Processing file: 0002.parquet\n",
      "Processing file: 0000.parquet\n",
      "Processing file: 0005.parquet\n",
      "Processing file: 0004.parquet\n",
      "Processing file: 0003.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'conversation_index.json'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_parquet_conversation_index(parquet_urls, headers, output_index_file=\"json/conversation_index.json\"):\n",
    "    \"\"\"\n",
    "    Builds an index of conversation IDs from a list of Parquet file URLs.\n",
    "    Stores the index as a JSON mapping conversation IDs to their respective file names.\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "\n",
    "    for url in parquet_urls:\n",
    "        file_name = url.split('/')[-1]  # Extract file name from URL\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "\n",
    "        try:\n",
    "            # Download the file temporarily\n",
    "            r = requests.get(url, headers=headers)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".parquet\", delete=False) as tmp:\n",
    "                tmp.write(r.content)\n",
    "                tmp_path = tmp.name\n",
    "\n",
    "            # Query conversation IDs using DuckDB\n",
    "            query = f\"SELECT conversation_id FROM read_parquet('{tmp_path}')\"\n",
    "            df = duckdb.query(query).to_df()\n",
    "\n",
    "            # Map conversation IDs to file name (not the full URL)\n",
    "            for _, row in df.iterrows():\n",
    "                index[row[\"conversation_id\"]] = file_name\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "    # Save index for fast lookup\n",
    "    with open(output_index_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(index, f, indent=2)\n",
    "\n",
    "    return output_index_file\n",
    "\n",
    "create_parquet_conversation_index(parquet_urls, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying file: 0003.parquet for 2 conversations\n",
      "Found 2 conversations in 0003.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3b0e49647811446b8b1585ccc3020a75</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[{'content': 'Give me the algorithm for a time...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e437eb3080954eae9f494057722c018d</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conversation_id           model  \\\n",
       "0  3b0e49647811446b8b1585ccc3020a75      alpaca-13b   \n",
       "1  e437eb3080954eae9f494057722c018d  fastchat-t5-3b   \n",
       "\n",
       "                                        conversation  turn language  \\\n",
       "0  [{'content': 'Give me the algorithm for a time...     2  English   \n",
       "1  [{'content': 'turn this leet speak into normal...     7  English   \n",
       "\n",
       "                                   openai_moderation  redacted  \n",
       "0  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "1  [{'categories': {'harassment': False, 'harassm...      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def extract_conversations_using_index(index_file, parquet_urls, conversation_ids, headers):\n",
    "    # Load the conversation index\n",
    "    with open(index_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        index = json.load(f)\n",
    "\n",
    "    # Create a lookup table for file names -> URLs\n",
    "    file_url_map = {url.split(\"/\")[-1]: url for url in parquet_urls}\n",
    "\n",
    "    # Group conversation IDs by file\n",
    "    file_to_conversations = defaultdict(list)\n",
    "    for convid in conversation_ids:\n",
    "        if convid in index:\n",
    "            file_to_conversations[index[convid]].append(convid)\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for file_name, conv_ids in file_to_conversations.items():\n",
    "        if file_name not in file_url_map:\n",
    "            print(f\"File {file_name} not found in URL list, skipping.\")\n",
    "            continue\n",
    "\n",
    "        file_url = file_url_map[file_name]\n",
    "        print(f\"Querying file: {file_name} for {len(conv_ids)} conversations\")\n",
    "\n",
    "        try:\n",
    "            # Download the file only once\n",
    "            r = requests.get(file_url, headers=headers)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".parquet\", delete=False) as tmp:\n",
    "                tmp.write(r.content)\n",
    "                tmp_path = tmp.name\n",
    "\n",
    "            # Construct a single query for all requested conversations\n",
    "            conv_id_list = \"', '\".join(conv_ids)\n",
    "            query_str = f\"\"\"\n",
    "                SELECT * FROM read_parquet('{tmp_path}') \n",
    "                WHERE conversation_id IN ('{conv_id_list}')\n",
    "            \"\"\"\n",
    "            df = duckdb.query(query_str).df()\n",
    "\n",
    "            if not df.empty:\n",
    "                print(f\"Found {len(df)} conversations in {file_name}\")\n",
    "                result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "conversation_ids = [\"e437eb3080954eae9f494057722c018d\", \"3b0e49647811446b8b1585ccc3020a75\"]\n",
    "auth_header = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "df = extract_conversations_using_index(\"json/conversation_index.json\", parquet_urls, conversation_ids, auth_header)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying file: 0003.parquet for 2 conversations\n",
      "Found 2 conversations in 0003.parquet\n",
      "Querying file: 0001.parquet for 1 conversations\n",
      "Found 1 conversations in 0001.parquet\n",
      "Querying file: 0000.parquet for 1 conversations\n",
      "Found 1 conversations in 0000.parquet\n",
      "Querying file: 0002.parquet for 1 conversations\n",
      "Found 1 conversations in 0002.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3b0e49647811446b8b1585ccc3020a75</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[{'content': 'Give me the algorithm for a time...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e437eb3080954eae9f494057722c018d</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'turn this leet speak into normal...</td>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab4f5c1d861e45fbb59b04c5c43ad7a4</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Tell me about yourself.', 'role'...</td>\n",
       "      <td>9</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a3b92d71a06459a9c60502947932022</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'This is a conversation that we h...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231794cbfdd94bcfab2cae2c0ca17eb5</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'why is time a paradox of distanc...</td>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conversation_id           model  \\\n",
       "0  3b0e49647811446b8b1585ccc3020a75      alpaca-13b   \n",
       "1  e437eb3080954eae9f494057722c018d  fastchat-t5-3b   \n",
       "2  ab4f5c1d861e45fbb59b04c5c43ad7a4      vicuna-13b   \n",
       "3  1a3b92d71a06459a9c60502947932022      vicuna-13b   \n",
       "4  231794cbfdd94bcfab2cae2c0ca17eb5      vicuna-13b   \n",
       "\n",
       "                                        conversation  turn language  \\\n",
       "0  [{'content': 'Give me the algorithm for a time...     2  English   \n",
       "1  [{'content': 'turn this leet speak into normal...     7  English   \n",
       "2  [{'content': 'Tell me about yourself.', 'role'...     9  English   \n",
       "3  [{'content': 'This is a conversation that we h...     1  English   \n",
       "4  [{'content': 'why is time a paradox of distanc...     7  English   \n",
       "\n",
       "                                   openai_moderation  redacted  \n",
       "0  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "1  [{'categories': {'harassment': False, 'harassm...      True  \n",
       "2  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "3  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "4  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation_ids = ['e437eb3080954eae9f494057722c018d', \n",
    "                    '3b0e49647811446b8b1585ccc3020a75',\n",
    "                    'ab4f5c1d861e45fbb59b04c5c43ad7a4',\n",
    "                    '1a3b92d71a06459a9c60502947932022',\n",
    "                    '231794cbfdd94bcfab2cae2c0ca17eb5'\n",
    "                    ]\n",
    "auth_header = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "df = extract_conversations_using_index(\"json/conversation_index.json\", parquet_urls, conversation_ids, auth_header)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
