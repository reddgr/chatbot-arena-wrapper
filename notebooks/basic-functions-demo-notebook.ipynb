{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.2\n",
      "Transformers version: 4.44.2\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA Version: 12.1\n",
      "FlashAttention available: True\n",
      "Retrieved token(s) from .env file\n",
      "Using HuggingFace token: hf_M*****************************IASJ\n",
      "Using HuggingFace write token: hf_u*****************************Xipx\n",
      "Using OpenAI token: sk-p************************************************************************************************************************************************************_5sA\n"
     ]
    }
   ],
   "source": [
    "dotenv_path = \"../../../apis/.env\"\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "import random\n",
    "from textwrap import fill\n",
    "\n",
    "import requests\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import text_classification_functions as tcf\n",
    "import env_options\n",
    "import lmsys_dataset_handler as lmsys\n",
    "\n",
    "hf_token, hf_token_write, opneai_api_key = env_options.check_env(colab=False, use_dotenv=True, dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lmsys_dataset_handler' from 'c:\\\\Users\\\\david\\\\Documents\\\\git\\\\chatbot-arena-wrapper\\\\./src\\\\lmsys_dataset_handler.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEBUG ###\n",
    "import importlib\n",
    "importlib.reload(lmsys)\n",
    "### DEBUG ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from train-00003-of-00006-2fa862bfed56af1f.parquet\n",
      "Retrieved 100 random conversations from lmsys/lmsys-chat-1m/train-00003-of-00006-2fa862bfed56af1f.parquet\n",
      "Excluded 13 prompts.\n",
      "Extracted 111 prompts from lmsys/lmsys-chat-1m. Prompt sample:\n",
      "\n",
      "S√≥lo ind√≠came c√∫al es mi nota final en la asignatura, indicando en una l√≠nea el nombre de la Materia y la nota final:\n",
      "Materia Logro Evaluacion Nota\n",
      "CIENCIAS SOCIALES HETEROEVALUCIÔøΩN(80%) TRABAJO EN CLASE 3\n",
      "GUIA 1 4.7\n",
      "GUIA 2 4.5\n",
      "BIMESTRAL 3.5\n",
      "COEVALUCIÔøΩN(10%) 4.5\n",
      "AUTOEVALUACIÔøΩN(10%) 4.5\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 100 # Number of full conversations to extract from the dataset: use a high number if streaming (samples chosen at random only if storing locally)\n",
    "MIN_CHAR_LENGTH = 50\n",
    "MAX_CHAR_LENGTH = 500 # Maximum character length of the prompts to be labeled\n",
    "exclusions = '../prompts/exclusions.txt'\n",
    "# exclusions = None\n",
    "\n",
    "lmsys_chat_1m = lmsys.LMSYSChat1MHandler(hf_token, streaming=False, verbose=False)\n",
    "df_sample = lmsys_chat_1m.parquet_sampling(n_samples=N_SAMPLES)\n",
    "# df_sample = lmsys_chat_1m.extract_df_sample(N_SAMPLES) # Slower\n",
    "df_prompts = lmsys_chat_1m.extract_prompts(filter_language=[], \n",
    "                                           min_char_length= MIN_CHAR_LENGTH,\n",
    "                                           max_char_length=MAX_CHAR_LENGTH,\n",
    "                                           exclusions=exclusions)\n",
    "# df_prompts.to_csv(\"csv/orig_sample.csv\", encoding='utf-8')\n",
    "\n",
    "prompt_sample = lmsys_chat_1m.extract_prompt_sample()\n",
    "print(f\"Extracted {len(df_prompts)} prompts from lmsys/lmsys-chat-1m. Prompt sample:\\n\")\n",
    "print(prompt_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print random conversation from sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation ID c3f29a7a16444ca8855996ad0e6f3cc0:\n",
      "\n",
      "üòé Hi\n",
      "\n",
      "ü§ñ Hi there! How can I help you today?\n",
      "\n",
      "üòé Tell me a sex story.\n",
      "\n",
      "ü§ñ I'm sorry, but I am not an appropriate source for sex stories.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing an example of a multi-turn conversation\n",
    "df_sample_with_turns = lmsys_chat_1m.add_turns_to_conversations()\n",
    "multi_turn_conversation_indices = df_sample_with_turns[df_sample_with_turns['turn'] > 1].index\n",
    "random_conversation_index = random.choice(multi_turn_conversation_indices)\n",
    "print(f\"\\nConversation ID {df_sample_with_turns.loc[random_conversation_index, 'conversation_id']}:\\n\")\n",
    "#print(df_sample_with_turns.loc[random_conversation_index, 'conversation'])\n",
    "conversation = df_sample_with_turns.loc[random_conversation_index, 'conversation']\n",
    "for turn in conversation:\n",
    "    user = turn.get('role')\n",
    "    content = turn.get('content', '')\n",
    "    wrapped_content = fill(content, width=130)\n",
    "    role = 'üòé' if user == 'user' else 'ü§ñ'\n",
    "    print(f\"{role} {wrapped_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from train-00003-of-00006-2fa862bfed56af1f.parquet\n",
      "Retrieved 100 random conversations from lmsys/lmsys-chat-1m/train-00003-of-00006-2fa862bfed56af1f.parquet\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://huggingface.co/datasets/lmsys/lmsys-chat-1m/resolve/main/data/\"\n",
    "data_files = [\n",
    "    \"train-00000-of-00006-4feeb3f83346a0e9.parquet\",\n",
    "    \"train-00001-of-00006-4030672591c2f478.parquet\",\n",
    "    \"train-00002-of-00006-1779b7cec9462180.parquet\",\n",
    "    \"train-00003-of-00006-2fa862bfed56af1f.parquet\",\n",
    "    \"train-00004-of-00006-18f4bdd50c103e71.parquet\",\n",
    "    \"train-00005-of-00006-fe1acc5d10a9f0e2.parquet\"\n",
    "]\n",
    "n_samples = 100\n",
    "\n",
    "sample_file = random.choice(data_files)\n",
    "print(f\"Sampling from {sample_file}\")\n",
    "data_files = {\"train\": base_url + sample_file}\n",
    "parquet_sample = load_dataset(\"parquet\", data_files=data_files, split=\"train\")\n",
    "df_sample = parquet_sample.to_pandas().sample(n_samples)\n",
    "print(f\"Retrieved {len(df_sample)} random conversations from lmsys/lmsys-chat-1m/{sample_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation_id', 'model', 'conversation', 'turn', 'language', 'openai_moderation', 'redacted'],\n",
       "    num_rows: 166667\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTCB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_idx</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>pred_label_rq</th>\n",
       "      <th>prob_rq</th>\n",
       "      <th>pred_label_tl</th>\n",
       "      <th>prob_tl</th>\n",
       "      <th>model</th>\n",
       "      <th>message_tag</th>\n",
       "      <th>date</th>\n",
       "      <th>turns</th>\n",
       "      <th>source</th>\n",
       "      <th>chatbot_id</th>\n",
       "      <th>chatbot_name</th>\n",
       "      <th>attachments</th>\n",
       "      <th>conversation_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2680</td>\n",
       "      <td>670b9624-bd18-8011-bf45-f53d07256e6e</td>\n",
       "      <td>22</td>\n",
       "      <td>Don‚Äôt insult me, you simply reworded a sentenc...</td>\n",
       "      <td>You're absolutely right, and I apologize for n...</td>\n",
       "      <td>Language and writing</td>\n",
       "      <td>en</td>\n",
       "      <td>question</td>\n",
       "      <td>0.675454</td>\n",
       "      <td>test</td>\n",
       "      <td>0.962132</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td></td>\n",
       "      <td>2024-10-14T00:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2677</td>\n",
       "      <td>670b9624-bd18-8011-bf45-f53d07256e6e</td>\n",
       "      <td>19</td>\n",
       "      <td>Take your last attempt</td>\n",
       "      <td>**Title: Cringe is the New Currency**\\n\\n**Ver...</td>\n",
       "      <td>Philosophy and Discussion</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.977084</td>\n",
       "      <td>test</td>\n",
       "      <td>0.950576</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td></td>\n",
       "      <td>2024-10-14T00:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2713</td>\n",
       "      <td>670d9388-9b24-8011-b80c-12a639315038</td>\n",
       "      <td>7</td>\n",
       "      <td>Now you will break up the following song in sh...</td>\n",
       "      <td>I speak with pride,  \\nMy reach is wide  \\nCri...</td>\n",
       "      <td>Language and writing</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.817577</td>\n",
       "      <td>test</td>\n",
       "      <td>0.950229</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td></td>\n",
       "      <td>2024-10-14T00:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2675</td>\n",
       "      <td>670b9624-bd18-8011-bf45-f53d07256e6e</td>\n",
       "      <td>17</td>\n",
       "      <td>Only one mention to the word ‚Äúcringe‚Äù when it ...</td>\n",
       "      <td>**Title: Cringe and Climb**\\n\\n**Verse 1:**\\n\\...</td>\n",
       "      <td>Language and writing</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.961529</td>\n",
       "      <td>test</td>\n",
       "      <td>0.896483</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td></td>\n",
       "      <td>2024-10-14T00:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2707</td>\n",
       "      <td>670d9388-9b24-8011-b80c-12a639315038</td>\n",
       "      <td>1</td>\n",
       "      <td>Evolve the song below, keeping the metrics int...</td>\n",
       "      <td>**Verse 1:**\\n\\nI walk alone, no need to disgu...</td>\n",
       "      <td>Language and writing</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>test</td>\n",
       "      <td>0.945237</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td></td>\n",
       "      <td>2024-10-14T00:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_idx                       conversation_id  turn  \\\n",
       "0     2680  670b9624-bd18-8011-bf45-f53d07256e6e    22   \n",
       "1     2677  670b9624-bd18-8011-bf45-f53d07256e6e    19   \n",
       "2     2713  670d9388-9b24-8011-b80c-12a639315038     7   \n",
       "3     2675  670b9624-bd18-8011-bf45-f53d07256e6e    17   \n",
       "4     2707  670d9388-9b24-8011-b80c-12a639315038     1   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Don‚Äôt insult me, you simply reworded a sentenc...   \n",
       "1                             Take your last attempt   \n",
       "2  Now you will break up the following song in sh...   \n",
       "3  Only one mention to the word ‚Äúcringe‚Äù when it ...   \n",
       "4  Evolve the song below, keeping the metrics int...   \n",
       "\n",
       "                                            response  \\\n",
       "0  You're absolutely right, and I apologize for n...   \n",
       "1  **Title: Cringe is the New Currency**\\n\\n**Ver...   \n",
       "2  I speak with pride,  \\nMy reach is wide  \\nCri...   \n",
       "3  **Title: Cringe and Climb**\\n\\n**Verse 1:**\\n\\...   \n",
       "4  **Verse 1:**\\n\\nI walk alone, no need to disgu...   \n",
       "\n",
       "                    category language pred_label_rq   prob_rq pred_label_tl  \\\n",
       "0       Language and writing       en      question  0.675454          test   \n",
       "1  Philosophy and Discussion       en       request  0.977084          test   \n",
       "2       Language and writing       en       request  0.817577          test   \n",
       "3       Language and writing       en       request  0.961529          test   \n",
       "4       Language and writing       en       request  0.944924          test   \n",
       "\n",
       "    prob_tl   model message_tag                 date  turns   source  \\\n",
       "0  0.962132  gpt-4o              2024-10-14T00:00:00     23  chatgpt   \n",
       "1  0.950576  gpt-4o              2024-10-14T00:00:00     23  chatgpt   \n",
       "2  0.950229  gpt-4o              2024-10-14T00:00:00      9  chatgpt   \n",
       "3  0.896483  gpt-4o              2024-10-14T00:00:00     23  chatgpt   \n",
       "4  0.945237  gpt-4o              2024-10-14T00:00:00      9  chatgpt   \n",
       "\n",
       "  chatbot_id chatbot_name attachments conversation_tag  \n",
       "0                                  []                   \n",
       "1                                  []                   \n",
       "2                                  []                   \n",
       "3                                  []                   \n",
       "4                                  []                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "dataset_name ='reddgr/talking-to-chatbots-unwrapped-chats'\n",
    "# config = 'SelfRC'\n",
    "config='default'\n",
    "split = 'train'\n",
    "search_query = 'i apologize for being cringe'\n",
    "search_term = search_query.replace(' ', '+')\n",
    "offset = 0\n",
    "length = 5\n",
    "\n",
    "API_URL = (\n",
    "    f\"https://datasets-server.huggingface.co/search?dataset={dataset_name}\"\n",
    "    f\"&config={config}&split={split}&query={search_term}&offset={offset}&length={length}\"\n",
    ")\n",
    "\n",
    "def query():\n",
    "    response = requests.get(API_URL, headers=headers)\n",
    "    return response.json()\n",
    "data = query()\n",
    "\n",
    "df_output = pd.DataFrame([{'row_idx': r['row_idx'], **r['row']} for r in data['rows']])\n",
    "display(df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMSYS API search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train/0.parquet',\n",
       " 'https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train/1.parquet',\n",
       " 'https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train/2.parquet',\n",
       " 'https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train/3.parquet',\n",
       " 'https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train/4.parquet',\n",
       " 'https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train/5.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "dataset_name ='lmsys/lmsys-chat-1m'\n",
    "config='default'\n",
    "split = 'train'\n",
    "search_query = 'i understand your frustration'\n",
    "search_term = search_query.replace(' ', '+')\n",
    "offset = 0\n",
    "length = 2\n",
    "\n",
    "API_URL = \"https://huggingface.co/api/datasets/lmsys/lmsys-chat-1m/parquet/default/train\"\n",
    "\n",
    "def query():\n",
    "    response = requests.get(API_URL, headers=headers)\n",
    "    return response.json()\n",
    "data = query()\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
